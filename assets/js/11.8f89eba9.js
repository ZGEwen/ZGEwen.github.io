(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{371:function(t,s,a){t.exports=a.p+"assets/img/output_8_0.7f731987.png"},372:function(t,s,a){t.exports=a.p+"assets/img/output_10_0.bb909ff0.png"},373:function(t,s,a){t.exports=a.p+"assets/img/output_12_0.ec151a60.png"},453:function(t,s,a){"use strict";a.r(s);var n=a(2),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("div",{staticClass:"custom-block tip"},[n("p",[t._v("示例：使用k-近邻算法改进约会网站的配对效果")])]),t._v(" "),n("p",[t._v("数据样本特征")]),t._v(" "),n("ul",[n("li",[t._v("每年获得的飞行常客里程数")]),t._v(" "),n("li",[t._v("玩视频游戏所耗时间百分比")]),t._v(" "),n("li",[t._v("每周消费的冰淇淋公升数")])]),t._v(" "),n("p",[t._v("流程")]),t._v(" "),n("ul",[n("li",[t._v("收集数据：提供文本数据")]),t._v(" "),n("li",[t._v("准备数据：使用Python解析文本文件")]),t._v(" "),n("li",[t._v("分析数据：使用matplotlib画二维扩散图")]),t._v(" "),n("li",[t._v("训练算法：k-近邻算法中测试数据每一次都要与全量的训练数据进行比较，此步骤不适用该算法")]),t._v(" "),n("li",[t._v("测试数据：使用提供的部分数据作为测试样本。测试样本是已经完成分类的数据。如果预测分类和实际分类不同，则标记为一个错误")]),t._v(" "),n("li",[t._v("使用算法：参数简单的命令行程序，输入一个特征数据以判断是否是喜欢的类型")])]),t._v(" "),n("h2",{attrs:{id:"_1-准备数据：从文本文件中解析数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-准备数据：从文本文件中解析数据"}},[t._v("#")]),t._v(" 1.准备数据：从文本文件中解析数据")]),t._v(" "),n("p",[t._v("数据文件："),n("code",[t._v("datingTestSet2.txt")])]),t._v(" "),n("p",[t._v("每个样本数据占据一行，样本数据包含以下三种特征：")]),t._v(" "),n("ol",[n("li",[t._v("每年获得的飞行常客里程数")]),t._v(" "),n("li",[t._v("玩视频游戏所消耗时间百分比")]),t._v(" "),n("li",[t._v("每周消费的冰淇淋公升数")])]),t._v(" "),n("p",[t._v("定义文件打开：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("open_file")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    打开文件\n    :param filename: 文件名称\n    :return: 文件内容list\n    """')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" fr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" fr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readlines"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br")])]),n("p",[t._v("将文本记录转换为Numpy：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("file2matrix")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    将文本记录转换为 NumPy\n    :param filename: 文件名称\n    :return: numpy矩阵\n    """')]),t._v("\n    fr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" open_file"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取文件中行数")]),t._v("\n    numberOfLines "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建返回的numpy矩阵")]),t._v("\n    returnMat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" zeros"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numberOfLines"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 解析文件数据保存到列表中")]),t._v("\n    classLabelVector "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    index "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" line "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" fr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# str.strip([chars]) --返回已移除字符串头尾指定字符（默认为空格或换行符）所生成的新字符串")]),t._v("\n        line "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strip"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以 '\\t' 切割字符串")]),t._v("\n        listFromLine "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" line"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每列的属性数据")]),t._v("\n        returnMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" listFromLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每列的类别数据，就是 label 标签数据")]),t._v("\n        classLabelVector"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("listFromLine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        index "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回数据矩阵returnMat和对应的类别classLabelVector")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" returnMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classLabelVector\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br")])]),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\nfilename "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/datingTestSet2.txt'")]),t._v("\ndatingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("datingLabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file2matrix"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br")])]),n("pre",[n("code",[t._v("[[4.0920000e+04 8.3269760e+00 9.5395200e-01]\n [1.4488000e+04 7.1534690e+00 1.6739040e+00]\n [2.6052000e+04 1.4418710e+00 8.0512400e-01]\n ...\n [2.6575000e+04 1.0650102e+01 8.6662700e-01]\n [4.8111000e+04 9.1345280e+00 7.2804500e-01]\n [4.3757000e+04 7.8826010e+00 1.3324460e+00]] [3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 3, 3, 1, 1, 1, 1, 2, 2, 1, 3, 2, 2, 2, 2, 3, 1, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 1, 2, 3, 2, 2, 1, 3, 1, 1, 3, 3, 1, 2, 3, 1, 3, 1, 2, 2, 1, 1, 3, 3, 1, 2, 1, 3, 3, 2, 1, 1, 3, 1, 2, 3, 3, 2, 3, 3, 1, 2, 3, 2, 1, 3, 1, 2, 1, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 3, 3, 1, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 1, 1, 3, 3, 2, 3, 3, 1, 2, 3, 2, 2, 3, 3, 3, 1, 2, 2, 1, 1, 3, 2, 3, 3, 1, 2, 1, 3, 1, 2, 3, 2, 3, 1, 1, 1, 3, 2, 3, 1, 3, 2, 1, 3, 2, 2, 3, 2, 3, 2, 1, 1, 3, 1, 3, 2, 2, 2, 3, 2, 2, 1, 2, 2, 3, 1, 3, 3, 2, 1, 1, 1, 2, 1, 3, 3, 3, 3, 2, 1, 1, 1, 2, 3, 2, 1, 3, 1, 3, 2, 2, 3, 1, 3, 1, 1, 2, 1, 2, 2, 1, 3, 1, 3, 2, 3, 1, 2, 3, 1, 1, 1, 1, 2, 3, 2, 2, 3, 1, 2, 1, 1, 1, 3, 3, 2, 1, 1, 1, 2, 2, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 3, 2, 3, 3, 3, 3, 1, 2, 3, 1, 1, 1, 3, 1, 3, 2, 2, 1, 3, 1, 3, 2, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 3, 3, 2, 3, 3, 2, 3, 1, 3, 1, 3, 3, 1, 3, 2, 1, 3, 1, 3, 2, 1, 2, 2, 1, 3, 1, 1, 3, 3, 2, 2, 3, 1, 2, 3, 3, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 3, 3, 3, 2, 3, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 1, 3, 2, 1, 3, 2, 1, 3, 1, 1, 3, 3, 3, 3, 2, 1, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 1, 2, 2, 2, 1, 1, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 3, 1, 1, 2, 2, 1, 2, 2, 2, 3, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 1, 1, 3, 2, 3, 3, 2, 2, 1, 1, 1, 2, 1, 2, 2, 3, 3, 3, 1, 1, 3, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 2, 3, 2, 1, 1, 1, 1, 3, 3, 3, 3, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 2, 1, 2, 2, 2, 3, 2, 1, 3, 2, 3, 2, 3, 2, 1, 1, 2, 3, 1, 3, 3, 3, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 1, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 3, 2, 3, 2, 3, 2, 3, 3, 2, 2, 1, 3, 1, 2, 1, 3, 1, 1, 1, 3, 1, 1, 3, 3, 2, 2, 1, 3, 1, 1, 3, 2, 3, 1, 1, 3, 1, 3, 3, 1, 2, 3, 1, 3, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 3, 1, 3, 1, 1, 2, 2, 2, 3, 2, 2, 1, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 1, 3, 2, 3, 2, 1, 2, 1, 1, 1, 2, 3, 2, 2, 1, 2, 2, 1, 3, 1, 3, 3, 3, 2, 2, 3, 3, 1, 2, 2, 2, 3, 1, 2, 1, 3, 1, 2, 3, 1, 1, 1, 2, 2, 3, 1, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 2, 3, 1, 3, 1, 2, 3, 2, 2, 3, 1, 2, 3, 2, 3, 1, 2, 2, 3, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 3, 2, 1, 3, 3, 3, 1, 1, 3, 1, 2, 3, 3, 2, 2, 2, 1, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 2, 1, 3, 3, 1, 2, 3, 2, 1, 3, 3, 3, 1, 2, 2, 2, 3, 2, 3, 3, 1, 2, 1, 1, 2, 1, 3, 1, 2, 2, 1, 3, 2, 1, 3, 3, 2, 2, 2, 1, 2, 2, 1, 3, 1, 3, 1, 3, 3, 1, 1, 2, 3, 2, 2, 3, 1, 1, 1, 1, 3, 2, 2, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 1, 3, 2, 3, 1, 1, 3, 3, 3, 3, 1, 3, 2, 2, 1, 1, 3, 3, 2, 2, 2, 1, 2, 1, 2, 1, 3, 2, 1, 2, 2, 3, 1, 2, 2, 2, 3, 2, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 1, 1, 3, 2, 1, 2, 1, 2, 2, 3, 2, 2, 2, 3, 1, 2, 1, 2, 2, 1, 1, 2, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 2, 3, 2, 3, 3, 2, 2, 1, 1, 1, 3, 3, 1, 1, 1, 3, 3, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 2, 3, 2, 2, 1, 3, 1, 2, 3, 1, 2, 2, 2, 2, 3, 2, 3, 3, 1, 2, 1, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 3, 3, 3]\n")])]),t._v(" "),n("h2",{attrs:{id:"_2-分析数据：使用matplotlib创建散点图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-分析数据：使用matplotlib创建散点图"}},[t._v("#")]),t._v(" 2.分析数据：使用Matplotlib创建散点图")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示中文")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'font.sans-serif'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SimHei'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置正常显示符号，解决保存图像是符号’-‘显示方块")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'axes.unicode_minus'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\nfig "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_subplot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("111")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'散点分析图:没有样本类别标签的约会数据散点图，难以辨别图中点究竟属于哪个样本分类'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_xlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'玩视频游戏所耗时间百分比'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_ylabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'每周消费的冰淇淋公升数'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])]),n("p",[n("img",{attrs:{src:a(371),alt:"png"}})]),t._v(" "),n("p",[t._v("采用色彩或其他的记号来标记不同的样本分类，以便更好的理解数据信息")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示中文")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'font.sans-serif'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SimHei'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置正常显示符号，解决保存图像是符号’-‘显示方块")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'axes.unicode_minus'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\nfig "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_subplot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("111")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'散点分析图:利用颜色和尺寸标识数据点的属性类别，基本可看出数据点所属三个样本分类的区域轮廓'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_xlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'玩视频游戏所耗时间百分比'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_ylabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'每周消费的冰淇淋公升数'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15.0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15.0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br")])]),n("p",[n("img",{attrs:{src:a(372),alt:"png"}})]),t._v(" "),n("p",[t._v("使用矩阵属性列0和1展示数据，可清晰的标识三种不同样本分类区域")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 显示中文")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'font.sans-serif'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SimHei'")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置正常显示符号，解决保存图像是符号’-‘显示方块")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rcParams"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'axes.unicode_minus'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\nfig "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_subplot"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("111")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_title"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'飞行常客里程数和玩视频游戏所占百分比的散点分析图，区分数据点从属的类别'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_xlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'每年获得的飞行常客里程数'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("set_ylabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'玩视频游戏所耗时间百分比'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndatingLabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# datingLabels为1的索引")]),t._v("\nindex_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("where"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntype_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nindex_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("where"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntype_2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'g'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nindex_3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("where"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntype_3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index_3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("index_3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("type_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("type_2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("type_3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'不喜欢'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'魅力一般'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'极具魅力'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("loc"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br")])]),n("p",[n("img",{attrs:{src:a(373),alt:"png"}})]),t._v(" "),n("h2",{attrs:{id:"_3-准备数据：归一化数值"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-准备数据：归一化数值"}},[t._v("#")]),t._v(" 3.准备数据：归一化数值")]),t._v(" "),n("p",[t._v("以下四组数据中：")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("序号")]),t._v(" "),n("th",{staticStyle:{"text-align":"center"}},[t._v("玩视频游戏所耗时间百分比")]),t._v(" "),n("th",{staticStyle:{"text-align":"right"}},[t._v("每年获得的飞行常客里程数")]),t._v(" "),n("th",{staticStyle:{"text-align":"right"}},[t._v("每周消费的冰淇淋公升数")]),t._v(" "),n("th",{staticStyle:{"text-align":"right"}},[t._v("样本分类")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("1")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("0.8")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("400")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("0.5")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("1")])]),t._v(" "),n("tr",[n("td",[t._v("2")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("12")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("134 000")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("0.9")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("3")])]),t._v(" "),n("tr",[n("td",[t._v("3")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("0")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("20 000")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("1.1")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("2")])]),t._v(" "),n("tr",[n("td",[t._v("4")]),t._v(" "),n("td",{staticStyle:{"text-align":"center"}},[t._v("67")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("32 000")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("0.1")]),t._v(" "),n("td",{staticStyle:{"text-align":"right"}},[t._v("2")])])])]),t._v(" "),n("p",[t._v("样本3和样本4之间的距离，可以采用欧式距离进行计算： $\\sqrt{(0-67)^{2}+(20000-32000)^{2}+(1.1-0.1)^{2}}$")]),t._v(" "),n("p",[t._v("数字差值最大的属性对计算结果的影响最大，在处理这种不同取值范围的特征值时，通常采用的方法是将数值"),n("code",[t._v("归一化")]),t._v("，如将取值范围经过处理为0-1或者-1到1之间。\n归一化特征值，消除特征之间量级不同导致的影响.\n归一化可以采用的方法有很多，这里使用线性函数转化：\nnewValue=(oldValue-MinValue)/(MaxValue-MinValue)　　\n其中：oldValue、newValue分别为转换前、后的值，MaxValue、MinValue分别为数据集中的最大特征值和最小特征值。")]),t._v(" "),n("p",[t._v("归一化特征值：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("autoNorm")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n     归一化特征值，消除特征之间量级不同导致的影响\n    :param dataSet: 数据集\n    :return:归一化后的数据集 normDataSet. ranges和minVals即范围和最小值\n    """')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算每列的最小值和最大值，dataSet.min(0)参数0使得函数从列中选取最小值而不是选取当前行的最小值")]),t._v("\n    minVals "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    maxVals "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 计算可能的取值范围 1*3")]),t._v("\n    ranges "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" maxVals "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" minVals\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1000*3")]),t._v("\n    normDataSet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" zeros"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shape[0]读取矩阵的第一维长度")]),t._v("\n    m "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生成与最小值之差组成的矩阵。tile()将变量内容复制成输入矩阵同大小的矩阵")]),t._v("\n    normDataSet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataSet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" tile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("minVals"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将最小值之差除以范围组成矩阵")]),t._v("\n    normDataSet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" normDataSet "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" tile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ranges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 特征值相除")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" normDataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ranges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" minVals\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br")])]),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ranges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" minVals "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" autoNorm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("normMat\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("pre",[n("code",[t._v("array([[0.44832535, 0.39805139, 0.56233353],\n       [0.15873259, 0.34195467, 0.98724416],\n       [0.28542943, 0.06892523, 0.47449629],\n       ...,\n       [0.29115949, 0.50910294, 0.51079493],\n       [0.52711097, 0.43665451, 0.4290048 ],\n       [0.47940793, 0.3768091 , 0.78571804]])\n")])]),t._v(" "),n("h2",{attrs:{id:"_4-测试算法：作为完整程序验证分类器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-测试算法：作为完整程序验证分类器"}},[t._v("#")]),t._v(" 4.测试算法：作为完整程序验证分类器")]),t._v(" "),n("p",[t._v("评估算法的正确率，选取已有数据的90%作为训练分类器，随机选取10%数据测试分类器，用来检测分类器的正确率。\n该示例中，提供的数据并没有按照特定目的来排序，所以可以随意选择10%数据而不影响随机性。")]),t._v(" "),n("p",[t._v("分类器对约会网站的测试代码：如果预测分类与实际类别不同，则出错次数加1。")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("classify0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    k-近邻算法\n    :param inX: 用于分类的输入向量\n    :param dataSet: 输入的训练样本集\n    :param labels: 标签向量\n    :param k: 表示用于选择最近邻居的数目\n    :return: 前k个点中出现频率最高的那个分类，作为当前点的预测分类\n    """')]),t._v("\n    dataSetSize "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 距离度量 度量公式为欧氏距离公式")]),t._v("\n    diffMat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tile"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inX"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataSetSize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" dataSet\n    sqDiffMat "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" diffMat"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n    sqDistances "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sqDiffMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    distances "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sqDistances"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将距离排序：从小到大")]),t._v("\n    sortedDistIndicies "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" distances"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argsort"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 选取前K个最短距离， 选取这K个中最多的分类类别")]),t._v("\n    classCount"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        voteIlabel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sortedDistIndicies"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        classCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("voteIlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" classCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("voteIlabel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n    sortedClassCount "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sorted")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("classCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("operator"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("itemgetter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" reverse"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" sortedClassCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("datingClassTest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    对约会网站的测试\n    :return: 错误率和错误数\n    """')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置测试数据的的一个比例（训练数据集比例=1-hoRatio）")]),t._v("\n    hoRatio "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 测试范围,一部分测试一部分作为样本")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 从文件中加载数据")]),t._v("\n    datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" datingLabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file2matrix"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/datingTestSet2.txt'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 归一化数据")]),t._v("\n    normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ranges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" minVals "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" autoNorm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# m 表示数据的行数，即矩阵的第一维")]),t._v("\n    m "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置测试的样本数量， numTestVecs:m表示训练样本的数量")]),t._v("\n    numTestVecs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" hoRatio"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'测试的样本数量numTestVecs='")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" numTestVecs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    errorCount "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numTestVecs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对数据测试")]),t._v("\n        classifierResult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" classify0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("numTestVecs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("numTestVecs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("classifierResult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n            errorCount "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string-interpolation"}},[n("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"预测分类为: ')]),n("span",{pre:!0,attrs:{class:"token interpolation"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("classifierResult"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v(",真正的分类为: ")]),n("span",{pre:!0,attrs:{class:"token interpolation"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string-interpolation"}},[n("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"错误率为: ')]),n("span",{pre:!0,attrs:{class:"token interpolation"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("errorCount "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numTestVecs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("errorCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" errorCount"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("errorCount "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("numTestVecs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br"),n("span",{staticClass:"line-number"},[t._v("15")]),n("br"),n("span",{staticClass:"line-number"},[t._v("16")]),n("br"),n("span",{staticClass:"line-number"},[t._v("17")]),n("br"),n("span",{staticClass:"line-number"},[t._v("18")]),n("br"),n("span",{staticClass:"line-number"},[t._v("19")]),n("br"),n("span",{staticClass:"line-number"},[t._v("20")]),n("br"),n("span",{staticClass:"line-number"},[t._v("21")]),n("br"),n("span",{staticClass:"line-number"},[t._v("22")]),n("br"),n("span",{staticClass:"line-number"},[t._v("23")]),n("br"),n("span",{staticClass:"line-number"},[t._v("24")]),n("br"),n("span",{staticClass:"line-number"},[t._v("25")]),n("br"),n("span",{staticClass:"line-number"},[t._v("26")]),n("br"),n("span",{staticClass:"line-number"},[t._v("27")]),n("br"),n("span",{staticClass:"line-number"},[t._v("28")]),n("br"),n("span",{staticClass:"line-number"},[t._v("29")]),n("br"),n("span",{staticClass:"line-number"},[t._v("30")]),n("br"),n("span",{staticClass:"line-number"},[t._v("31")]),n("br"),n("span",{staticClass:"line-number"},[t._v("32")]),n("br"),n("span",{staticClass:"line-number"},[t._v("33")]),n("br"),n("span",{staticClass:"line-number"},[t._v("34")]),n("br"),n("span",{staticClass:"line-number"},[t._v("35")]),n("br"),n("span",{staticClass:"line-number"},[t._v("36")]),n("br"),n("span",{staticClass:"line-number"},[t._v("37")]),n("br"),n("span",{staticClass:"line-number"},[t._v("38")]),n("br"),n("span",{staticClass:"line-number"},[t._v("39")]),n("br"),n("span",{staticClass:"line-number"},[t._v("40")]),n("br"),n("span",{staticClass:"line-number"},[t._v("41")]),n("br"),n("span",{staticClass:"line-number"},[t._v("42")]),n("br"),n("span",{staticClass:"line-number"},[t._v("43")]),n("br"),n("span",{staticClass:"line-number"},[t._v("44")]),n("br"),n("span",{staticClass:"line-number"},[t._v("45")]),n("br"),n("span",{staticClass:"line-number"},[t._v("46")]),n("br"),n("span",{staticClass:"line-number"},[t._v("47")]),n("br"),n("span",{staticClass:"line-number"},[t._v("48")]),n("br"),n("span",{staticClass:"line-number"},[t._v("49")]),n("br"),n("span",{staticClass:"line-number"},[t._v("50")]),n("br"),n("span",{staticClass:"line-number"},[t._v("51")]),n("br")])]),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" operator\ndatingClassTest"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br")])]),n("pre",[n("code",[t._v("测试的样本数量numTestVecs= 100\n预测分类为: 3,真正的分类为: 2\n预测分类为: 3,真正的分类为: 1\n预测分类为: 3,真正的分类为: 1\n预测分类为: 2,真正的分类为: 3\n预测分类为: 3,真正的分类为: 1\n错误率为: 0.05\n5.0\n\n\n\n\n\n(5.0, 0.05)\n")])]),t._v(" "),n("h2",{attrs:{id:"_5-使用算法：构建完整可用系统"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_5-使用算法：构建完整可用系统"}},[t._v("#")]),t._v(" 5.使用算法：构建完整可用系统")]),t._v(" "),n("p",[t._v("产生简单的程序，可以通过输入一些特征数据给出对对方喜欢程度的预测值")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("classifyPerson")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    约会网站预测函数\n    :return: 预测结果\n    """')]),t._v("\n    resultList "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'not at all不喜欢的人'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'in small doses魅力一般的人'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'in large doses极具魅力的人'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    ffMiles "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"每年获得的飞行常客里程数?"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    percentTats "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"玩视频游戏所耗费时间百分比?"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    iceCream "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"每周消费的冰淇淋公升数?"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" datingLabels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" file2matrix"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data/datingTestSet2.txt'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ranges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" minVals "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" autoNorm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datingDataMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    inArr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ffMiles"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" percentTats"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" iceCream"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    classifierResult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" classify0"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inArr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" minVals"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" ranges"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normMat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" datingLabels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string-interpolation"}},[n("span",{pre:!0,attrs:{class:"token string"}},[t._v('f"在你看来，对方很可能是: ')]),n("span",{pre:!0,attrs:{class:"token interpolation"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("resultList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("classifierResult "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br"),n("span",{staticClass:"line-number"},[t._v("2")]),n("br"),n("span",{staticClass:"line-number"},[t._v("3")]),n("br"),n("span",{staticClass:"line-number"},[t._v("4")]),n("br"),n("span",{staticClass:"line-number"},[t._v("5")]),n("br"),n("span",{staticClass:"line-number"},[t._v("6")]),n("br"),n("span",{staticClass:"line-number"},[t._v("7")]),n("br"),n("span",{staticClass:"line-number"},[t._v("8")]),n("br"),n("span",{staticClass:"line-number"},[t._v("9")]),n("br"),n("span",{staticClass:"line-number"},[t._v("10")]),n("br"),n("span",{staticClass:"line-number"},[t._v("11")]),n("br"),n("span",{staticClass:"line-number"},[t._v("12")]),n("br"),n("span",{staticClass:"line-number"},[t._v("13")]),n("br"),n("span",{staticClass:"line-number"},[t._v("14")]),n("br")])]),n("p",[t._v("实际运行效果如下：")]),t._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("classifyPerson"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[t._v("1")]),n("br")])]),n("pre",[n("code",[t._v("每年获得的飞行常客里程数? 10000\n玩视频游戏所耗费时间百分比? 10\n每周消费的冰淇淋公升数? 0.5\n\n\n在你看来，对方很可能是: in small doses魅力一般的人\n")])])])}),[],!1,null,null,null);s.default=e.exports}}]);